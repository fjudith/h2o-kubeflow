# Copyright (c) Jupyter Development Team.
# Distributed under the terms of the Modified BSD License.
ARG BASE_IMAGE=ubuntu:18.04@sha256:de774a3145f7ca4f0bd144c7d4ffb2931e06634f11529653b23eba85aef8e378

FROM $BASE_IMAGE

LABEL maintainer='Florian JUDITH <florian.judith.b@gmail.com>'

ARG TF_PACKAGE=https://files.pythonhosted.org/packages/77/63/a9fa76de8dffe7455304c4ed635be4aa9c0bacef6e0633d87d5f54530c5c/tensorflow-1.13.1-cp36-cp36m-manylinux1_x86_64.whl
ARG TF_PACKAGE_PY_27=https://files.pythonhosted.org/packages/d2/ea/ab2c8c0e81bd051cc1180b104c75a865ab0fc66c89be992c4b20bbf6d624/tensorflow-1.13.1-cp27-cp27mu-manylinux1_x86_64.whl
ARG TF_SERVING_VERSION=0.0.0
ARG TFMA_VERSION=0.13.0
ARG TFDV_VERSION=0.13.1
ARG PIPELINE_SDK_PACKAGE=https://storage.googleapis.com/ml-pipeline/release/0.1.8/kfp.tar.gz

USER root

ENV DEBIAN_FRONTEND noninteractive

ENV NB_USER jovyan
ENV NB_UID 1000
ENV HOME /home/$NB_USER
ENV NB_PREFIX /
# We prefer to have a global conda install
# to minimize the amount of content in $HOME
ENV CONDA_DIR=/opt/conda
ENV PATH $CONDA_DIR/bin:$PATH

# Export args as environment variables.
# This is solely to make them available to install.sh
ENV TF_PACKAGE $TF_PACKAGE
ENV TF_PACKAGE_27 $TF_PACKAGE_PY_27
ENV TF_SERVING_VERSION $TF_PACKAGE_PY_27
ENV TFMA_VERSION $TFMA_VERSION
ENV TFDV_VERSION $TFDV_VERSION
ENV PIPELINE_SDK_PACKAGE $PIPELINE_SDK_PACKAGE

# Use bash instead of sh
SHELL ["/bin/bash", "-c"]

# Install all OS dependencies for notebook server that starts but lacks all
# features (e.g., download as all possible file formats)
ENV DEBIAN_FRONTEND noninteractive

RUN apt-get update && apt-get install -yq --no-install-recommends \
    apt-transport-https \
    build-essential \
    bzip2 \
    ca-certificates \
    curl \
    g++ \
    git \
    gnupg \
    graphviz \
    jed \
    ffmpeg \
    libcupti-dev \
    locales \
    lsb-release \
    openssh-client \
    pkg-config \
    python \
    python-dev \
    sudo \
    unzip \
    vim \
    wget \
    zlib1g-dev \
    zip && \
    apt-get autoremove -y --purge && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

ENV DOCKER_CREDENTIAL_GCR_VERSION=1.4.3
RUN curl -LO https://github.com/GoogleCloudPlatform/docker-credential-gcr/releases/download/v${DOCKER_CREDENTIAL_GCR_VERSION}/docker-credential-gcr_linux_amd64-${DOCKER_CREDENTIAL_GCR_VERSION}.tar.gz && \
    tar -zxvf docker-credential-gcr_linux_amd64-${DOCKER_CREDENTIAL_GCR_VERSION}.tar.gz && \
    mv docker-credential-gcr /usr/local/bin/docker-credential-gcr && \
    rm docker-credential-gcr_linux_amd64-${DOCKER_CREDENTIAL_GCR_VERSION}.tar.gz && \
    chmod +x /usr/local/bin/docker-credential-gcr

RUN echo "en_US.UTF-8 UTF-8" > /etc/locale.gen && \
    locale-gen

ENV LC_ALL en_US.UTF-8
ENV LANG en_US.UTF-8
ENV LANGUAGE en_US.UTF-8

# Create jovyan user with UID=1000 and in the 'users' group
# but allow for non-initial launches of the notebook to have
# $HOME provided by the contents of a PV
RUN useradd -M -s /bin/bash -N -u $NB_UID $NB_USER && \
    chown -R ${NB_USER}:users /usr/local/bin && \
    mkdir -p $HOME

RUN export CLOUD_SDK_REPO="cloud-sdk-$(lsb_release -c -s)" && \
    echo "deb https://packages.cloud.google.com/apt $CLOUD_SDK_REPO main" > /etc/apt/sources.list.d/google-cloud-sdk.list && \
    curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - && \
    apt-get update && \
    apt-get install -y google-cloud-sdk kubectl && \
    apt-get autoremove -y --purge && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/* && \
    gcloud config set core/disable_usage_reporting true && \
    gcloud config set component_manager/disable_update_check true && \
    gcloud config set metrics/environment github_docker_image

# Install Tini - used as entrypoint for container
RUN cd /tmp && \
    wget --quiet https://github.com/krallin/tini/releases/download/v0.18.0/tini && \
    echo "12d20136605531b09a2c2dac02ccee85e1b874eb322ef6baf7561cd93f93c855 *tini" | sha256sum -c - && \
    mv tini /usr/local/bin/tini && \
    chmod +x /usr/local/bin/tini

# Install conda as jovyan user and check the md5 sum provided on the download site
# After Miniconda v4.5.4 the default Python version is no longer 3.6, but TensorFlow
# still doesn't support Python 3.7. If we still like to upgrade Miniconda we need
# to add the line "conda install python==3.6" to RUN command below
ENV MINICONDA_VERSION 4.5.4
RUN cd /tmp && \
    mkdir -p $CONDA_DIR && \
    wget --quiet https://repo.continuum.io/miniconda/Miniconda3-${MINICONDA_VERSION}-Linux-x86_64.sh && \
    echo "a946ea1d0c4a642ddf0c3a26a18bb16d *Miniconda3-${MINICONDA_VERSION}-Linux-x86_64.sh" | md5sum -c - && \
    /bin/bash Miniconda3-${MINICONDA_VERSION}-Linux-x86_64.sh -f -b -p ${CONDA_DIR} && \
    rm Miniconda3-${MINICONDA_VERSION}-Linux-x86_64.sh && \
    conda config --system --prepend channels conda-forge && \
    conda config --system --set auto_update_conda false && \
    conda config --system --set show_channel_urls true && \
    conda update --all && \
    conda update conda && \
    conda clean -tipsy

# NOTE: Beyond this point be careful of breaking out
# or otherwise adding new layers with RUN, chown, etc.
# The image size can grow significantly.

# Install base python3 packages
RUN pip install --upgrade pip==19.0.1 && \
    pip --no-cache-dir install \
    # Tensorflow
    ${TF_PACKAGE} \
    # Jupyter Stuff
    jupyter \
    jupyter-console==6.0.0 \
    jupyterhub \
    jupyterlab \
    xgboost \
    git+https://github.com/kubeflow/fairing@a9bb9d5cc1c9f1d75efa31198ddbdccfe176b7bf \
    # Kubeflow pipeline SDK
    ${PIPELINE_SDK_PACKAGE} \
    # Cleanup
    && conda clean -tipsy

# NB: the COPY chown can't expand a bash variable for NB_USER
COPY --chown=jovyan:users requirements.txt /tmp

# Install python2 and ipython2 kernel for jupyter notebook
# Install tf packages which only support py2
COPY --chown=jovyan:users install.sh /tmp/
RUN chmod a+rx /tmp/install.sh && \
    /tmp/install.sh

##################################################
# H2O
##################################################

# Install ksonnet
ENV KSONNET_VERSION 0.13.0
RUN curl -L https://github.com/ksonnet/ksonnet/releases/download/v${KSONNET_VERSION}/ks_${KSONNET_VERSION}_linux_amd64.tar.gz | tar -xvzf - && \
    mv ks_${KSONNET_VERSION}_linux_amd64/ks /usr/local/bin/ks && \
    rm -rf ks_${KSONNET_VERSION}_linux_amd64 && \
    chmod +x /usr/local/bin/ks

# Install CUDA Profile Tools and other python packages
# h5py, ipykernet, matplotlib and sklearn are already installed by install.sh and requirements.txt
RUN apt-get update && apt-get install -yq --no-install-recommends \
    gcc-6 g++-6 && \
    apt-get autoremove -y --purge && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/* && \
    mkdir -p /usr/local/cuda/bin/ && \
    ln -s $(which gcc-6) /usr/local/cuda/bin/gcc && \
    ln -s $(which g++-6) /usr/local/cuda/bin/g++ && \
    pip -v --no-cache-dir install \
    Pillow \
    numpy \
    scipy \
    kubernetes \
    grpcio \
    # ktext
    annoy \
    nltk \
    pydot \
    pydot-ng \
    graphviz \
    ipyparallel && \
    python -m ipykernel.kernelspec

# Install Python 3 packages
# Remove pyqt and qt pulled in for matplotlib since we're only ever going to
# use notebook-friendly backends in these images
# ipywidgets, pandas, matplotlib and h5py are already installed by install.sh and requirements.txt
RUN conda install -vv --yes \
    'nomkl' \
    'numexpr=2.6*' \
    'scipy=0.19*' \
    'seaborn=0.7*' \
    'scikit-learn=0.18*' \
    'scikit-image=0.12*' \
    'sympy=1.0*' \
    'cython=0.25*' \
    'patsy=0.4*' \
    'statsmodels=0.8*' \
    'cloudpickle=0.2*' \
    'dill=0.2*' \
    'numba=0.31*' \
    'bokeh=0.12*' \
    'sqlalchemy=1.1*' \
    'hdf5=1.8.17' \
    'vincent=0.4.*' \
    'beautifulsoup4=4.5.*' \
    'xlrd'  && \
    conda remove --quiet --yes --force qt pyqt && \
    conda clean -tipsy

# Install graphviz package
RUN apt-get update && apt-get install -yq --no-install-recommends graphviz && \
    apt-get autoremove -y --purge && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Install Oracle Java 8
RUN \
  apt-get update && apt-get install -y wget unzip python-pip python-sklearn python-pandas python-numpy python-matplotlib software-properties-common && \
  apt-get update -q && \
  DEBIAN_FRONTEND=noninteractive apt-get install -y openjdk-8-jdk && \
  apt-get autoremove -y --purge && \
  apt-get clean && \
  rm -rf /var/lib/apt/lists/*

# Install H2O.3
RUN pip --no-cache-dir install \
        requests \
        tabulate \
        scikit-learn \
        colorama \
        future
RUN pip --no-cache-dir --trusted-host h2o-release.s3.amazonaws.com install -f \
        http://h2o-release.s3.amazonaws.com/h2o/latest_stable_Py.html h2o

# Activate ipywidgets extension in the environment that runs the notebook server
RUN jupyter nbextension enable --py widgetsnbextension --sys-prefix

ENV BAZEL_VERSION=0.25.2
RUN curl -L -o bazel.sh https://github.com/bazelbuild/bazel/releases/download/${BAZEL_VERSION}/bazel-${BAZEL_VERSION}-installer-linux-x86_64.sh && chmod a+x ./bazel.sh && ./bazel.sh && rm ./bazel.sh
SHELL ["/bin/bash", "-c"]

RUN git clone https://github.com/tensorflow/models.git /home/$NB_USER/tensorflow-models && git clone https://github.com/tensorflow/benchmarks.git /home/$NB_USER/tensorflow-benchmarks
# Import matplotlib the first time to build the font cache.
ENV XDG_CACHE_HOME /home/$NB_USER/.cache/
RUN pip install jupyter-tensorboard

# Create a conda environment for Python 2. We want to include as many of the
# packages from our root environment as we reasonably can, so we explicitly
# list that environment, then include everything unless it is Conda (which
# can only be in the root environment), Jupyterhub (which requires Python 3),
# or Python itself. We also want to include the pip packages, but we cannot
# install those via conda, so we list them, drop any conda packages, and
# then install them via pip. We do this on a best-effort basis, so if any
# packages from the Python 3 environment cannot be installed with Python 2,
# then we just skip them.
# RUN conda_packages=$(conda list -e | cut -d '=' -f 1 | grep -v '#' | sort) && \
#     pip_packages=$(pip --no-cache-dir list --format=freeze | cut -d '=' -f 1 | grep -v '#' | sort) && \
#     pip_only_packages=$(comm -23 <(echo "${pip_packages}") <(echo "${conda_packages}")) && \
#     conda create -n ipykernel_py2 python=2 --file <(echo "${conda_packages}" | grep -v conda | grep -v python | grep -v jupyterhub) && \
#     source activate ipykernel_py2 && \
#     python -m ipykernel install --user && \
#     echo "${pip_only_packages}" | xargs -n 1 -I "{}" /bin/bash -c 'pip install --no-cache-dir {} || true' && \
#     pip install --no-cache-dir tensorflow-transform && \
#     source deactivate

##################################################

# Add basic config
COPY --chown=jovyan:users  jupyter_notebook_config.py /tmp

# Wipe $HOME for PVC detection later
WORKDIR $HOME
RUN rm -fr $(ls -A $HOME)

# Copy over init scripts
COPY --chown=jovyan:users  pvc-check.sh /usr/local/bin/
RUN chmod a+rx /usr/local/bin/*

RUN docker-credential-gcr configure-docker && chown jovyan:users $HOME/.docker/config.json

# Configure container startup
EXPOSE 8888
USER jovyan
ENTRYPOINT ["tini", "--"]
CMD ["sh","-c", "jupyter notebook --notebook-dir=/home/jovyan --ip=0.0.0.0 --no-browser --allow-root --port=8888 --NotebookApp.token='' --NotebookApp.password='' --NotebookApp.allow_origin='*' --NotebookApp.base_url=${NB_PREFIX}"]

